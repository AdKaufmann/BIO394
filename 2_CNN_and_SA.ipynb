{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "directory = '/Users/adriankaufmann/Desktop/RGBimages_trainingset/'\n",
    "categories = ['negative_all', 'positive_all']\n",
    "\n",
    "#path to positive/negative directory\n",
    "for category in categories:\n",
    "    path = os.path.join(directory, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path, img))#, cv2.IMREAD_GRAYSCALE)\n",
    "        plt.imshow(img_array)\n",
    "        plt.show\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "\n",
    "\n",
    "for category in categories:\n",
    "    path = os.path.join(directory, category)\n",
    "    class_num = categories.index(category) #negative should be zero now\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path, img))#, cv2.IMREAD_GRAYSCALE)\n",
    "        #new_array = cv2.resize(img_array, (WIDTH, LENTH))\n",
    "        training_data.append([img_array, class_num])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting rid of the 'corrupted' images (need to find out why they occured)\n",
    "training = []\n",
    "for c,i in enumerate(training_data):\n",
    "    if i[0] is not None:\n",
    "        training.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pack it into parameters to feed neural network\n",
    "\n",
    "X = [] #feature set\n",
    "y = [] #labels\n",
    "\n",
    "for features, label in training:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle the data, to mix up the two categories\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "\n",
    "X, y = shuffle(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SEQUENCE PADDING\n",
    "for c,i in enumerate(X):\n",
    "    X[c] = tf.image.resize_with_pad(i, 698, 133, method=tf.image.ResizeMethod.BILINEAR, antialias=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert X list into array\n",
    "\n",
    "X = np.array(X).astype(np.float32) #.reshape(-1,698,3)#.astype('float32') #(all features, colors)\n",
    "y = np.array(y).astype(np.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the data (between 0 and 1)\n",
    "X = X.astype(\"float\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into test and validation subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), input_shape= (698,133,3))) #X.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  #convert 3D feature maps to 1D feature vectors\n",
    "\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(660, 698, 133, 3)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y, batch_size=4, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cf_matrix_all = confusion_matrix(y_test, predictions)\n",
    "print(cf_matrix_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# plot the matrix\n",
    "cax = ax.matshow(cf_matrix_all)\n",
    "\n",
    "# add colorbar for reference\n",
    "fig.colorbar(cax)\n",
    "\n",
    "cm = confusion_matrix(y_test, predictions, y)\n",
    "\n",
    "# add labels to plot\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "\n",
    "accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "misclass = 1 - accuracy\n",
    "plt.xlabel('Predicted label\\naccuracy={:0.3f}; misclass={:0.1f}'.format(accuracy, misclass))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulated annealing (SA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# random sequence (length 100aa) with average amino acid composition (computed from Swiss-Prot)\n",
    "# from: https://web.expasy.org/randseq/\n",
    "antigenseq = \"RVQPTESIVRFPNITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPCNGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNF\"\n",
    "\n",
    "\n",
    "#ran_seq = 'MAQVQLVESGGALVQPGGSLRLSCAASGFPVNRYSMRWYRQAPGKEREWVAGMSSAGDRSSYEDSVKGRFTISRDDARNTVYLQMNSLKPEDTAVYYCNVNVGFEYWGQGTQVTVSSHHHHHH' \n",
    "ran_seq = 'EFQQVGPIICTRSTTFLTAPRFNWPYNDKPNTERNIEKIGLDGASEIVLAIGEVVRAEVSLNLEADAEVGAKMYTRPGVYLHHGSTAKLLAFKVAQSDKDLAFSGRLPKLQVRIDMILGHLQESYCSMDS' \n",
    "dictionary = {\"D\": 0,\"E\": 1,\"C\": 2,\"N\": 3,\"F\": 4,\"Q\": 5,\"Y\": 6,\"S\": 7, \"M\": 8,\"T\": 9,\"I\": 10,\"G\": 11,\"V\": 12,\"W\": 13,\"L\": 14,\"A\": 15,\"P\": 16,\"H\": 17,\"K\": 18,\"R\": 19}\n",
    "\n",
    "seq_onehot = AAseq(ran_seq, dictionary)\n",
    "charge_onehot = AAcharge(ran_seq, antigenseq, dictionary, charge_df)\n",
    "hydroph_onehot = AAhydroph(ran_seq, antigenseq, dictionary, hydroph_df)\n",
    "\n",
    "X_original = cv2.imread(img)\n",
    "\n",
    "a = np.array(seq_onehot)\n",
    "b = np.array(charge_onehot)\n",
    "c = np.array(hydroph_onehot)\n",
    "\n",
    "X_array = np.dstack([a,b,c])\n",
    "X_original = tf.image.resize_with_pad(X_array, 698, 163, method=tf.image.ResizeMethod.BILINEAR, antialias=False)\n",
    "X_original = np.array(X_original).astype(np.float32)\n",
    "X_original = X_original.reshape(X_original.shape[0], X_original.shape[1], X_original.shape[2])\n",
    "X_original = X_original.astype(\"float\") / 255.0\n",
    "\n",
    "pred_init = model.predict( np.array( [X_original,]))[0][0]\n",
    "\n",
    "\n",
    "\n",
    "print(pred_init)\n",
    "pred = 0\n",
    "count = 0\n",
    "c = 0\n",
    "\n",
    "pred_best = 0\n",
    "seq_best = ''\n",
    "\n",
    "while pred < 0.95:\n",
    "\n",
    "    temp_seq = ran_seq\n",
    "    \n",
    "    letter = random.choice(list(dictionary))\n",
    "    number = random.randint(0,len(ran_seq)-1)\n",
    "    mut_seq = list(ran_seq)\n",
    "    mut_seq[number] = letter\n",
    "    mut_seq = ''.join(mut_seq)\n",
    "    \n",
    "    \n",
    "    seq_onehot = AAseq(mut_seq, dictionary)\n",
    "    charge_onehot = AAcharge(mut_seq, antigenseq, dictionary, charge_df)\n",
    "    hydroph_onehot = AAhydroph(mut_seq, antigenseq, dictionary, hydroph_df)\n",
    "\n",
    "    X_opt = cv2.imread(img)\n",
    "\n",
    "    a = np.array(seq_onehot)\n",
    "    b = np.array(charge_onehot)\n",
    "    c = np.array(hydroph_onehot)\n",
    "\n",
    "    X_array = np.dstack([a,b,c])\n",
    "    X_opt = tf.image.resize_with_pad(X_array, 698, 163, method=tf.image.ResizeMethod.BILINEAR, antialias=False)\n",
    "    X_opt = np.array(X_opt).astype(np.float32)\n",
    "    X_opt = X_opt.reshape(X_opt.shape[0], X_opt.shape[1], X_opt.shape[2])\n",
    "    X_opt = X_opt.astype(\"float\") / 255.0\n",
    "\n",
    "    pred = model.predict( np.array( [X_opt,]))[0][0]\n",
    "\n",
    "    delta_pred = abs(pred - pred_init)\n",
    "    \n",
    "    if pred > pred_init:\n",
    "        \n",
    "        if pred > pred_best:\n",
    "            seq_best = mut_seq\n",
    "            pred_best = pred\n",
    "            print(pred_best, seq_best)\n",
    "        \n",
    "        ran_seq = mut_seq\n",
    "       \n",
    "    \n",
    "    elif random.uniform(0, 1) < math.exp(-delta_pred):\n",
    "        ran_seq = mut_seq\n",
    "    else:\n",
    "        ran_seq = temp_seq\n",
    "        \n",
    "    \n",
    "    pred_init = pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
